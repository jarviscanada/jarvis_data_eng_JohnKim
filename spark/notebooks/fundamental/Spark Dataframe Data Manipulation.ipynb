{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53193039-ba28-4c23-92e7-d4109013bb0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Learning Objectives\n",
    "In this notebook, you will learn Spark Dataframe APIs.\n",
    "\n",
    "# Question List\n",
    "\n",
    "Solve the following questions using Spark Dataframe APIs\n",
    "\n",
    "### Join\n",
    "\n",
    "1. easy - https://pgexercises.com/questions/joins/simplejoin.html\n",
    "2. easy - https://pgexercises.com/questions/joins/simplejoin2.html\n",
    "3. easy - https://pgexercises.com/questions/joins/self2.html \n",
    "4. medium - https://pgexercises.com/questions/joins/threejoin.html (three join)\n",
    "5. medium - https://pgexercises.com/questions/joins/sub.html (subquery and join)\n",
    "\n",
    "### Aggregation\n",
    "\n",
    "1. easy - https://pgexercises.com/questions/aggregates/count3.html Group by order by\n",
    "2. easy - https://pgexercises.com/questions/aggregates/fachours.html group by order by\n",
    "3. easy - https://pgexercises.com/questions/aggregates/fachoursbymonth.html group by with condition \n",
    "4. easy - https://pgexercises.com/questions/aggregates/fachoursbymonth2.html group by multi col\n",
    "5. easy - https://pgexercises.com/questions/aggregates/members1.html count distinct\n",
    "6. med - https://pgexercises.com/questions/aggregates/nbooking.html group by multiple cols, join\n",
    "\n",
    "### String & Date\n",
    "\n",
    "1. easy - https://pgexercises.com/questions/string/concat.html format string\n",
    "2. easy - https://pgexercises.com/questions/string/case.html WHERE + string function\n",
    "3. easy - https://pgexercises.com/questions/string/reg.html WHERE + string function\n",
    "4. easy - https://pgexercises.com/questions/string/substr.html group by, substr\n",
    "5. easy - https://pgexercises.com/questions/date/series.html generate ts\n",
    "6. easy - https://pgexercises.com/questions/date/bookingspermonth.html extract month from ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ef02ac8-3ff6-48b8-9524-fffcb6cabdf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3a40767-4122-43d6-887e-9667a5ffb19a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Retrieve the start times of members' bookings\n",
    "How can you produce a list of the start times for bookings by members named 'David Farrell'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e132f54d-46c8-421d-97b3-5db87cdb8b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n|          starttime|\n+-------------------+\n|2012-09-18 09:00:00|\n|2012-09-18 17:30:00|\n|2012-09-18 13:30:00|\n|2012-09-18 20:00:00|\n|2012-09-19 09:30:00|\n|2012-09-19 15:00:00|\n|2012-09-19 12:00:00|\n|2012-09-20 15:30:00|\n|2012-09-20 11:30:00|\n|2012-09-20 14:00:00|\n|2012-09-21 10:30:00|\n|2012-09-21 14:00:00|\n|2012-09-22 08:30:00|\n|2012-09-22 17:00:00|\n|2012-09-23 08:30:00|\n|2012-09-23 17:30:00|\n|2012-09-23 19:00:00|\n|2012-09-24 08:00:00|\n|2012-09-24 16:30:00|\n|2012-09-24 12:30:00|\n+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "bookings_df = spark.table(\"bookings\")\n",
    "members_df = spark.table(\"members\")\n",
    "\n",
    "result_df = bookings_df.join(members_df, bookings_df.memid == members_df.memid)\n",
    "result_df = result_df.filter((col(\"surname\") == \"Farrell\") & (col(\"firstname\") == \"David\")).select(\"starttime\")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b651c438-17ca-4906-9d90-bfc9a79fd9eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Work out the start times of bookings for tennis courts\n",
    "How can you produce a list of the start times for bookings for tennis courts, for the date '2012-09-21'? Return a list of start time and facility name pairings, ordered by the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6f83d22-fa66-49ca-ae77-9e4cafc9d44b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n|          starttime|          name|\n+-------------------+--------------+\n|2012-09-21 08:00:00|Tennis Court 1|\n|2012-09-21 08:00:00|Tennis Court 2|\n|2012-09-21 09:30:00|Tennis Court 1|\n|2012-09-21 10:00:00|Tennis Court 2|\n|2012-09-21 11:30:00|Tennis Court 2|\n|2012-09-21 12:00:00|Tennis Court 1|\n|2012-09-21 13:30:00|Tennis Court 1|\n|2012-09-21 14:00:00|Tennis Court 2|\n|2012-09-21 15:30:00|Tennis Court 1|\n|2012-09-21 16:00:00|Tennis Court 2|\n|2012-09-21 17:00:00|Tennis Court 1|\n|2012-09-21 18:00:00|Tennis Court 2|\n+-------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "facilities_df = spark.table(\"facilities\")\n",
    "\n",
    "result_df = facilities_df.join(bookings_df, bookings_df.facid == facilities_df.facid)\n",
    "result_df = result_df.filter((col(\"name\").isin(\"Tennis Court 1\", \"Tennis Court 2\")) & (to_date(col(\"starttime\")) == \"2012-09-21\")).select(\"starttime\", \"name\").orderBy(\"starttime\")\n",
    "\n",
    "result_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f604992e-6197-4c8b-9ff9-7373ce040b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Produce a list of all members, along with their recommender\n",
    "How can you output a list of all members, including the individual who recommended them (if any)? Ensure that results are ordered by (surname, firstname)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fc288b7-2bcd-465c-b2d4-a4a851e6ccbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------------+-------------------+\n|firstname|  surname|recommender_firstname|recommender_surname|\n+---------+---------+---------------------+-------------------+\n| Florence|    Bader|               Ponder|           Stibbons|\n|     Anne|    Baker|               Ponder|           Stibbons|\n|  Timothy|    Baker|               Jemima|            Farrell|\n|      Tim|   Boothe|                  Tim|             Rownam|\n|   Gerald|  Butters|               Darren|              Smith|\n|     Joan|   Coplin|              Timothy|              Baker|\n|    Erica|  Crumpet|                Tracy|              Smith|\n|    Nancy|     Dare|               Janice|           Joplette|\n|  Matthew|  Genting|               Gerald|            Butters|\n|     John|     Hunt|            Millicent|            Purview|\n|    David|    Jones|               Janice|           Joplette|\n|  Douglas|    Jones|                David|              Jones|\n|   Janice| Joplette|               Darren|              Smith|\n|     Anna|Mackenzie|               Darren|              Smith|\n|  Charles|     Owen|               Darren|              Smith|\n|    David|   Pinker|               Jemima|            Farrell|\n|Millicent|  Purview|                Tracy|              Smith|\n|Henrietta|   Rumney|              Matthew|            Genting|\n|Ramnaresh|   Sarwin|             Florence|              Bader|\n|     Jack|    Smith|               Darren|              Smith|\n+---------+---------+---------------------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result_df = (members_df.alias(\"m1\").join(members_df.alias(\"m2\"),col(\"m1.recommendedby\") == col(\"m2.memid\")))\n",
    "result_df = result_df.select(\n",
    "        col(\"m1.firstname\"),\n",
    "        col(\"m1.surname\"),\n",
    "        col(\"m2.firstname\").alias(\"recommender_firstname\"),\n",
    "        col(\"m2.surname\").alias(\"recommender_surname\")\n",
    "    ).orderBy(col(\"m1.surname\"), col(\"m1.firstname\"))\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa28239-fe7f-45cd-b037-322eec50741e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Produce a list of all members who have used a tennis court\n",
    "How can you produce a list of all members who have used a tennis court? Include in your output the name of the court, and the name of the member formatted as a single column. Ensure no duplicate data, and order by the member name followed by the facility name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123adc2d-4117-4dc1-b984-8e124ddfa6ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n| facility_name|   member_name|\n+--------------+--------------+\n|Tennis Court 1|    Anne Baker|\n|Tennis Court 2|    Anne Baker|\n|Tennis Court 1|  Burton Tracy|\n|Tennis Court 2|  Burton Tracy|\n|Tennis Court 1|  Charles Owen|\n|Tennis Court 2|  Charles Owen|\n|Tennis Court 2|  Darren Smith|\n|Tennis Court 1| David Farrell|\n|Tennis Court 2| David Farrell|\n|Tennis Court 1|   David Jones|\n|Tennis Court 2|   David Jones|\n|Tennis Court 1|  David Pinker|\n|Tennis Court 1| Douglas Jones|\n|Tennis Court 1| Erica Crumpet|\n|Tennis Court 1|Florence Bader|\n|Tennis Court 2|Florence Bader|\n|Tennis Court 1|   GUEST GUEST|\n|Tennis Court 2|   GUEST GUEST|\n|Tennis Court 1|Gerald Butters|\n|Tennis Court 2|Gerald Butters|\n+--------------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "result_df = (bookings_df.join(facilities_df, col(\"bookings.facid\") == col(\"facilities.facid\")).join(members_df, col(\"bookings.memid\") == col(\"members.memid\")))\n",
    "result_df = result_df.filter(col(\"name\").isin(\"Tennis Court 1\", \"Tennis Court 2\")).select(\n",
    "        col(\"name\").alias(\"facility_name\"), \n",
    "        concat_ws(\" \", col(\"firstname\"), col(\"surname\")).alias(\"member_name\")\n",
    "    ).distinct().orderBy(\"member_name\", \"facility_name\")  # Order by member name, then facility name\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0aad33-f3e4-4d94-af12-c3531a33ee8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Produce a list of all members, along with their recommender, using no joins.\n",
    "How can you output a list of all members, including the individual who recommended them (if any), without using any joins? Ensure that there are no duplicates in the list, and that each firstname + surname pairing is formatted as a column and ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e57b5f75-8d1b-44f4-8e03-383682fd1788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n|              member|      recommender|\n+--------------------+-----------------+\n|      Anna Mackenzie|     Darren Smith|\n|          Anne Baker|  Ponder Stibbons|\n|        Charles Owen|     Darren Smith|\n|         David Jones|  Janice Joplette|\n|        David Pinker|   Jemima Farrell|\n|       Douglas Jones|      David Jones|\n|       Erica Crumpet|      Tracy Smith|\n|      Florence Bader|  Ponder Stibbons|\n|      Gerald Butters|     Darren Smith|\n|    Henrietta Rumney|  Matthew Genting|\n|Henry Worthington...|      Tracy Smith|\n|          Jack Smith|     Darren Smith|\n|     Janice Joplette|     Darren Smith|\n|         Joan Coplin|    Timothy Baker|\n|           John Hunt|Millicent Purview|\n|     Matthew Genting|   Gerald Butters|\n|   Millicent Purview|      Tracy Smith|\n|          Nancy Dare|  Janice Joplette|\n|     Ponder Stibbons|     Burton Tracy|\n|    Ramnaresh Sarwin|   Florence Bader|\n+--------------------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result_df = (members_df.alias(\"m1\").join(members_df.alias(\"m2\"),col(\"m1.recommendedby\") == col(\"m2.memid\")))\n",
    "result_df = result_df.select(\n",
    "        concat_ws(\" \", col(\"m1.firstname\"), col(\"m1.surname\")).alias(\"member\"),\n",
    "        concat_ws(\" \", col(\"m2.firstname\"), col(\"m2.surname\")).alias(\"recommender\")\n",
    "    ).distinct().orderBy(\"member\")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db301876-c6c3-403a-9a16-56a026de580a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a301a6d2-898f-4b47-a129-1d654aba3786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Count the number of recommendations each member makes.\n",
    "Produce a count of the number of recommendations each member has made. Order by member ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "708d6b7e-0d3d-463a-b70e-14a8781d152f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n|recommendedby|count|\n+-------------+-----+\n|            1|    5|\n|            2|    3|\n|            3|    1|\n|            4|    2|\n|            5|    1|\n|            6|    1|\n|            9|    2|\n|           11|    1|\n|           13|    2|\n|           15|    1|\n|           16|    1|\n|           20|    1|\n|           30|    1|\n+-------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "result_df = (\n",
    "    members_df.filter(col(\"recommendedby\").isNotNull())\n",
    "    .groupBy(\"recommendedby\")\n",
    "    .count()\n",
    "    .orderBy(\"recommendedby\")\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0b0426-dde3-43d7-833a-af2a114b8590",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. List the total slots booked per facility\n",
    "Produce a list of the total number of slots booked per facility. For now, just produce an output table consisting of facility id and slots, sorted by facility id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "464f4963-05bf-47e6-9da6-9746c8277229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n|facid|Total Slots|\n+-----+-----------+\n|    0|       1320|\n|    1|       1278|\n|    2|       1209|\n|    3|        830|\n|    4|       1404|\n|    5|        228|\n|    6|       1104|\n|    7|        908|\n|    8|        911|\n+-----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "result_df = (\n",
    "    bookings_df.groupBy(\"facid\")\n",
    "    .agg(sum(col(\"slots\")).alias(\"Total Slots\"))\n",
    "    .orderBy(\"facid\") \n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f015e4-0612-44a3-ac84-253561aba69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. List the total slots booked per facility in a given month\n",
    "Produce a list of the total number of slots booked per facility in the month of September 2012. Produce an output table consisting of facility id and slots, sorted by the number of slots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7bf53ff-989a-457f-98f0-8eb15f1e30e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n|facid|total_slots|\n+-----+-----------+\n|    5|        122|\n|    3|        422|\n|    7|        426|\n|    8|        471|\n|    6|        540|\n|    2|        570|\n|    1|        588|\n|    0|        591|\n|    4|        648|\n+-----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "filtered_df = bookings_df.filter(\n",
    "    (col(\"starttime\") >= \"2012-09-01\") & (col(\"starttime\") < \"2012-10-01\")\n",
    ")\n",
    "\n",
    "result_df = (\n",
    "    filtered_df.groupBy(\"facid\")\n",
    "    .agg(sum(\"slots\").alias(\"total_slots\"))  # Sum the slots\n",
    "    .orderBy(\"total_slots\")  # Order by total slots\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76af9a25-dddf-4513-aa59-dbd49dc7e737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. List the total slots booked per facility per month\n",
    "Produce a list of the total number of slots booked per facility per month in the year of 2012. Produce an output table consisting of facility id and slots, sorted by the id and month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6fa0a6-814d-4e3d-9e42-241a1325f5be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------+\n|facid|month|total_slots|\n+-----+-----+-----------+\n|    0|    7|        270|\n|    0|    8|        459|\n|    0|    9|        591|\n|    1|    7|        207|\n|    1|    8|        483|\n|    1|    9|        588|\n|    2|    7|        180|\n|    2|    8|        459|\n|    2|    9|        570|\n|    3|    7|        104|\n|    3|    8|        304|\n|    3|    9|        422|\n|    4|    7|        264|\n|    4|    8|        492|\n|    4|    9|        648|\n|    5|    7|         24|\n|    5|    8|         82|\n|    5|    9|        122|\n|    6|    7|        164|\n|    6|    8|        400|\n+-----+-----+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import  month\n",
    "\n",
    "# Filter for bookings in the year 2012\n",
    "filtered_df = bookings_df.filter(\n",
    "    (col(\"starttime\") >= \"2012-01-01\") & (col(\"starttime\") < \"2013-01-01\")\n",
    ")\n",
    "\n",
    "result_df = (\n",
    "    filtered_df.withColumn(\"month\", month(col(\"starttime\"))) \n",
    "    .groupBy(\"facid\", \"month\")\n",
    "    .agg(sum(\"slots\").alias(\"total_slots\"))\n",
    "    .orderBy(\"facid\", \"month\")\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8b6c707-e137-416b-9534-d87b9f9e8fda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Find the count of members who have made at least one booking\n",
    "Find the total number of members (including guests) who have made at least one booking.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "162cad91-7290-4a55-b8f1-8806dc3c0a3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Members: 30\n"
     ]
    }
   ],
   "source": [
    "total_members = bookings_df.select(\"memid\").distinct().count()\n",
    "\n",
    "print(f\"Total Members: {total_members}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83c6c79-1a70-4274-8d7c-5c5d00f97139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. List each member's first booking after September 1st 2012\n",
    "Produce a list of each member name, id, and their first booking after September 1st 2012. Order by member ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52009c9d-dc4d-4324-aec8-23d389b66812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+-------------------+\n|  surname|firstname|memid|      first_booking|\n+---------+---------+-----+-------------------+\n|    GUEST|    GUEST|    0|2012-09-01 08:00:00|\n|    Smith|   Darren|    1|2012-09-01 09:00:00|\n|    Smith|    Tracy|    2|2012-09-01 11:30:00|\n|   Rownam|      Tim|    3|2012-09-01 16:00:00|\n| Joplette|   Janice|    4|2012-09-01 15:00:00|\n|  Butters|   Gerald|    5|2012-09-02 12:30:00|\n|    Tracy|   Burton|    6|2012-09-01 15:00:00|\n|     Dare|    Nancy|    7|2012-09-01 12:30:00|\n|   Boothe|      Tim|    8|2012-09-01 08:30:00|\n| Stibbons|   Ponder|    9|2012-09-01 11:00:00|\n|     Owen|  Charles|   10|2012-09-01 11:00:00|\n|    Jones|    David|   11|2012-09-01 09:30:00|\n|    Baker|     Anne|   12|2012-09-01 14:30:00|\n|  Farrell|   Jemima|   13|2012-09-01 09:30:00|\n|    Smith|     Jack|   14|2012-09-01 11:00:00|\n|    Bader| Florence|   15|2012-09-01 10:30:00|\n|    Baker|  Timothy|   16|2012-09-01 15:00:00|\n|   Pinker|    David|   17|2012-09-01 08:30:00|\n|  Genting|  Matthew|   20|2012-09-01 18:00:00|\n|Mackenzie|     Anna|   21|2012-09-01 08:30:00|\n+---------+---------+-----+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, min\n",
    "\n",
    "filtered_bookings_df = bookings_df.filter(col(\"starttime\") >= \"2012-09-01\")\n",
    "\n",
    "joined_df = members_df.alias(\"m\").join(filtered_bookings_df.alias(\"b\"), col(\"m.memid\") == col(\"b.memid\"))\n",
    "\n",
    "result_df = (\n",
    "    joined_df.groupBy(col(\"m.surname\"), col(\"m.firstname\"), col(\"m.memid\"))\n",
    "    .agg(min(col(\"b.starttime\")).alias(\"first_booking\"))\n",
    "    .orderBy(col(\"m.memid\"))\n",
    ")\n",
    "\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0418d6-db09-4664-99c1-2369686ad3eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# String & Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67edf193-4436-4a66-ad4f-292508a05d42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Format the names of members\n",
    "Output the names of all members, formatted as 'Surname, Firstname'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0238594e-8cac-444d-9d16-a7b642589987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n|     member_name|\n+----------------+\n|    GUEST, GUEST|\n|   Smith, Darren|\n|    Smith, Tracy|\n|     Rownam, Tim|\n|Joplette, Janice|\n| Butters, Gerald|\n|   Tracy, Burton|\n|     Dare, Nancy|\n|     Boothe, Tim|\n|Stibbons, Ponder|\n|   Owen, Charles|\n|    Jones, David|\n|     Baker, Anne|\n| Farrell, Jemima|\n|     Smith, Jack|\n| Bader, Florence|\n|  Baker, Timothy|\n|   Pinker, David|\n|Genting, Matthew|\n| Mackenzie, Anna|\n+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result_df = members_df.select(concat_ws(\", \", col(\"surname\"), col(\"firstname\")).alias(\"member_name\"))\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad750c3-e3ce-4dfa-8a12-0fc0bea63205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Perform a case-insensitive search\n",
    "Perform a case-insensitive search to find all facilities whose name begins with 'tennis'. Retrieve all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b20e1a-d2ae-4897-b667-6e553f950e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+----------+---------+-------------+------------------+\n|facid|          name|membercost|guestcost|initialoutlay|monthlymaintenance|\n+-----+--------------+----------+---------+-------------+------------------+\n|    0|Tennis Court 1|       5.0|     25.0|        10000|               200|\n|    1|Tennis Court 2|       5.0|     25.0|         8000|               200|\n+-----+--------------+----------+---------+-------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "result_df = facilities_df.filter(lower(col(\"name\")).startswith(\"tennis\"))\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6f9f2c-7c03-4fff-9fae-fb27cbfad861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Find telephone numbers with parentheses\n",
    "You've noticed that the club's member table has telephone numbers with very inconsistent formatting. You'd like to find all the telephone numbers that contain parentheses, returning the member ID and telephone number sorted by member ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f365b5-1849-4dcc-891c-523c5c7dcc59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n|memid|     telephone|\n+-----+--------------+\n|    0|(000) 000-0000|\n|    3|(844) 693-0723|\n|    4|(833) 942-4710|\n|    5|(844) 078-4130|\n|    6|(822) 354-9973|\n|    7|(833) 776-4001|\n|    8|(811) 433-2547|\n|    9|(833) 160-3900|\n|   10|(855) 542-5251|\n|   11|(844) 536-8036|\n|   13|(855) 016-0163|\n|   14|(822) 163-3254|\n|   15|(833) 499-3527|\n|   20|(811) 972-1377|\n|   21|(822) 661-2898|\n|   22|(822) 499-2232|\n|   24|(822) 413-1470|\n|   27|(822) 989-8876|\n|   28|(855) 755-9876|\n|   29|(855) 894-3758|\n+-----+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result_df = members_df.filter(col(\"telephone\").rlike(r\"\\(.*\\)\")) \\\n",
    "                      .select(\"memid\", \"telephone\") \\\n",
    "                      .orderBy(\"memid\")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c09a3af7-6cf8-4182-ab94-1517ab0e63ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Count the number of members whose surname starts with each letter of the alphabet\n",
    "You'd like to produce a count of how many members you have whose surname starts with each letter of the alphabet. Sort by the letter, and don't worry about printing out a letter if the count is 0.![](path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1af332eb-5d0e-4538-ba6b-818c19afd4cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|first_letter|count|\n+------------+-----+\n|           B|    5|\n|           C|    2|\n|           D|    1|\n|           F|    2|\n|           G|    2|\n|           H|    1|\n|           J|    3|\n|           M|    1|\n|           O|    1|\n|           P|    2|\n|           R|    2|\n|           S|    6|\n|           T|    2|\n|           W|    1|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "\n",
    "result_df = (\n",
    "    members_df.groupBy(substring(col(\"surname\"), 1, 1).alias(\"first_letter\"))\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"first_letter\")\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f10c700-878c-437f-a287-42a402ac5daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Generate a list of all the dates in October 2012\n",
    "Produce a list of all the dates in October 2012. They can be output as a timestamp (with time set to midnight) or a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e141a9e-d788-4022-8476-bb202785be4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|        ts|\n+----------+\n|2012-10-01|\n|2012-10-02|\n|2012-10-03|\n|2012-10-04|\n|2012-10-05|\n|2012-10-06|\n|2012-10-07|\n|2012-10-08|\n|2012-10-09|\n|2012-10-10|\n|2012-10-11|\n|2012-10-12|\n|2012-10-13|\n|2012-10-14|\n|2012-10-15|\n|2012-10-16|\n|2012-10-17|\n|2012-10-18|\n|2012-10-19|\n|2012-10-20|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sequence, to_date, explode, lit\n",
    "\n",
    "result_df = (\n",
    "    spark.createDataFrame([(\"2012-10-01\", \"2012-10-31\")], [\"start\", \"end\"])\n",
    "    .select(explode(sequence(to_date(lit(\"2012-10-01\")), to_date(lit(\"2012-10-31\")))).alias(\"ts\"))\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0688ca6e-2f7b-413f-956a-0636711e0f17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Return a count of bookings for each month\n",
    "Return a count of bookings for each month, sorted by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c90a41-015b-4908-88a4-a69110090341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n|     month|booking_count|\n+----------+-------------+\n|2012-07-01|          658|\n|2012-08-01|         1472|\n|2012-09-01|         1913|\n|2013-01-01|            1|\n+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trunc\n",
    "\n",
    "df = (\n",
    "    bookings_df.withColumn(\"month\", trunc(\"starttime\", \"month\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(count(\"*\").alias(\"booking_count\"))\n",
    "    .orderBy(\"month\")\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1 - Spark Dataframe Data Manipulation (pgexercises)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}